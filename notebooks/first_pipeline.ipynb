{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9f2539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded!\n",
      "  N_FOLDS=5, N_TRIALS=30\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 1: CONFIGURATION & IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Configuration - À MODIFIER ICI\n",
    "N_FOLDS = 5\n",
    "N_TRIALS = 30\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Modèles à utiliser\n",
    "CLF_MODELS = [\"XGB\", \"LGBM\", \"CatBoost\", \"RF\", \"LR\", \"LDA\", \"QDA\", \"LinearSVC\", \"ElasticNetLR\"]\n",
    "REG_MODELS = [\"XGB\", \"LGBM\", \"CatBoost\", \"Ridge\", \"ElasticNet\", \"PLS\", \"KernelRidge\"]\n",
    "IPCW_MODELS = [\"XGB\", \"LGBM\", \"CatBoost\", \"RF\", \"Ridge\", \"ElasticNet\", \"PLS\", \"KernelRidge\"]\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Imports du module training\n",
    "from ens_data_challenge.training import (\n",
    "    transform_y,\n",
    "    scale_01,\n",
    "    FoldMetrics,\n",
    "    CVResults,\n",
    "    compute_ipcw_cindex,\n",
    "    get_classifier_factory,\n",
    "    get_regressor_factory,\n",
    "    train_classifier_cv,\n",
    "    train_regressor_cv,\n",
    "    train_ensemble,\n",
    "    get_ipcw_weights,\n",
    ")\n",
    "from ens_data_challenge.preprocess import Preprocessor\n",
    "\n",
    "print(\"Configuration loaded!\")\n",
    "print(f\"  N_FOLDS={N_FOLDS}, N_TRIALS={N_TRIALS}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7205e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA fitted for PATHWAY with 8 components.\n",
      "PCA fitted for GENE with 20 components.\n",
      "Data loaded!\n",
      "  X_clinical: (3173, 56)\n",
      "  X_cyto: (2758, 12)\n",
      "  Event rate: 0.504\n",
      "\n",
      "Feature Engineering ajouté:\n",
      "  - Nmut (nombre de mutations)\n",
      "  - Ratios: wbc_anc_ratio, plt_hb_ratio, blast_cyto_complexity, tumor_burden_composite\n",
      "  - Severity: cytopenias_count\n",
      "  - Molecular encoding: PATHWAY (confidence_weighted + effect), GENE (constant)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 2: DATA LOADING & PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "# Charger les données via globals\n",
    "from ens_data_challenge.globals import (\n",
    "    TRAIN_CLINICAL_DATA_PATH,\n",
    "    TRAIN_MOLECULAR_DATA_PATH,\n",
    "    TRAIN_TARGET_PATH,\n",
    "    TEST_CLINICAL_DATA_PATH,\n",
    "    TEST_MOLECULAR_DATA_PATH,\n",
    ")\n",
    "from ens_data_challenge.feature_engineering import FeatureEngineerHelper\n",
    "\n",
    "clinical_train = pd.read_csv(TRAIN_CLINICAL_DATA_PATH)\n",
    "clinical_test = pd.read_csv(TEST_CLINICAL_DATA_PATH)\n",
    "molecular_train = pd.read_csv(TRAIN_MOLECULAR_DATA_PATH)\n",
    "molecular_test = pd.read_csv(TEST_MOLECULAR_DATA_PATH)\n",
    "targets_train = pd.read_csv(TRAIN_TARGET_PATH)\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "# Get cyto features\n",
    "clinical_train, cyto_struct_train = preprocessor.get_cyto_features_and_df(\n",
    "    clinical_train\n",
    ")\n",
    "clinical_test, cyto_struct_test = preprocessor.get_cyto_features_and_df(clinical_test)\n",
    "\n",
    "# Fit transform\n",
    "(\n",
    "    clinical_preprocess_train,\n",
    "    clinical_preprocess_test,\n",
    "    molecular_preprocess_train,\n",
    "    molecular_preprocess_test,\n",
    "    cyto_struct_train,\n",
    "    cyto_struct_test,\n",
    "    targets_preprocess,\n",
    ") = preprocessor.fit_transform(\n",
    "    clinical_train,\n",
    "    clinical_test,\n",
    "    molecular_train,\n",
    "    molecular_test,\n",
    "    cyto_struct_train,\n",
    "    cyto_struct_test,\n",
    "    targets_train,\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE ENGINEERING avec FeatureEngineerHelper\n",
    "# =============================================================================\n",
    "feat_helper = FeatureEngineerHelper()\n",
    "\n",
    "# 1. Ajouter Nmut (nombre de mutations par patient)\n",
    "clinical_preprocess_train = feat_helper.Nmut(\n",
    "    molecular_preprocess_train, clinical_preprocess_train\n",
    ")\n",
    "clinical_preprocess_test = feat_helper.Nmut(\n",
    "    molecular_preprocess_test, clinical_preprocess_test\n",
    ")\n",
    "\n",
    "# 2. Ajouter ratios et interactions (WBC/ANC, PLT/HB, blast_cyto_complexity, tumor_burden_composite)\n",
    "clinical_preprocess_train = feat_helper.ratios_and_interactions(\n",
    "    clinical_preprocess_train\n",
    ")\n",
    "clinical_preprocess_test = feat_helper.ratios_and_interactions(clinical_preprocess_test)\n",
    "\n",
    "# 3. Ajouter severity scores (cytopenias_count)\n",
    "clinical_preprocess_train = feat_helper.severity_scores(clinical_preprocess_train)\n",
    "clinical_preprocess_test = feat_helper.severity_scores(clinical_preprocess_test)\n",
    "\n",
    "# 4. Ajouter encodage moléculaire par PATHWAY (confidence_weighted avec effect weighting)\n",
    "clinical_preprocess_train = feat_helper.fit_transform_mol_encoding(\n",
    "    clinical_data=clinical_preprocess_train,\n",
    "    molecular_data=molecular_preprocess_train,\n",
    "    col=\"PATHWAY\",\n",
    "    method=\"confidence_weighted\",\n",
    "    apply_effect_weighting=True,\n",
    ")\n",
    "clinical_preprocess_test = feat_helper.transform_mol_encoding(\n",
    "    clinical_data=clinical_preprocess_test,\n",
    "    molecular_data=molecular_preprocess_test,\n",
    "    col=\"PATHWAY\",\n",
    "    method=\"confidence_weighted\",\n",
    "    apply_effect_weighting=True,\n",
    ")\n",
    "\n",
    "# 5. Ajouter encodage moléculaire par GENE (constant pour baseline)\n",
    "clinical_preprocess_train = feat_helper.fit_transform_mol_encoding(\n",
    "    clinical_data=clinical_preprocess_train,\n",
    "    molecular_data=molecular_preprocess_train,\n",
    "    col=\"GENE\",\n",
    "    method=\"constant\",\n",
    "    apply_effect_weighting=False,\n",
    "    n_pca_components=20,\n",
    ")\n",
    "clinical_preprocess_test = feat_helper.transform_mol_encoding(\n",
    "    clinical_data=clinical_preprocess_test,\n",
    "    molecular_data=molecular_preprocess_test,\n",
    "    col=\"GENE\",\n",
    "    method=\"constant\",\n",
    "    apply_effect_weighting=False,\n",
    ")\n",
    "\n",
    "# Prepare data\n",
    "drop_columns = [ \"ID\", \"CENTER\", ]\n",
    "y_times = targets_preprocess[\"OS_YEARS\"].values\n",
    "events = targets_preprocess[\"OS_STATUS\"].values\n",
    "\n",
    "X_clinical = (\n",
    "    clinical_preprocess_train.drop(columns=drop_columns, errors=\"ignore\")\n",
    "    .copy()\n",
    "    .fillna(0)\n",
    "    .replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )  # Remplacer les inf créés par les divisions (ex: WBC/ANC quand ANC=0)\n",
    ")\n",
    "X_cyto = cyto_struct_train.drop(columns=[\"ID\"], errors=\"ignore\").fillna(\"UNKNOWN\")\n",
    "\n",
    "# Supprimer les colonnes catégorielles (garder uniquement les colonnes numériques)\n",
    "categorical_cols = X_clinical.select_dtypes(\n",
    "    include=[\"object\", \"category\"]\n",
    ").columns.tolist()\n",
    "if categorical_cols:\n",
    "    print(f\"Dropping categorical columns: {categorical_cols}\")\n",
    "    X_clinical = X_clinical.drop(columns=categorical_cols)\n",
    "\n",
    "print(f\"Data loaded!\")\n",
    "print(f\"  X_clinical: {X_clinical.shape}\")\n",
    "print(f\"  X_cyto: {X_cyto.shape}\")\n",
    "print(f\"  Event rate: {events.mean():.3f}\")\n",
    "print(f\"\\nFeature Engineering ajouté:\")\n",
    "print(f\"  - Nmut (nombre de mutations)\")\n",
    "print(\n",
    "    f\"  - Ratios: wbc_anc_ratio, plt_hb_ratio, blast_cyto_complexity, tumor_burden_composite\"\n",
    ")\n",
    "print(f\"  - Severity: cytopenias_count\")\n",
    "print(\n",
    "    f\"  - Molecular encoding: PATHWAY (confidence_weighted + effect), GENE (constant)\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "738fe8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BM_BLAST</th>\n",
       "      <th>WBC</th>\n",
       "      <th>ANC</th>\n",
       "      <th>HB</th>\n",
       "      <th>PLT</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>ploidy</th>\n",
       "      <th>has_tp53_deletion</th>\n",
       "      <th>has_complex_chr3</th>\n",
       "      <th>n_abnormalities</th>\n",
       "      <th>...</th>\n",
       "      <th>GENE_PCA_10</th>\n",
       "      <th>GENE_PCA_11</th>\n",
       "      <th>GENE_PCA_12</th>\n",
       "      <th>GENE_PCA_13</th>\n",
       "      <th>GENE_PCA_14</th>\n",
       "      <th>GENE_PCA_15</th>\n",
       "      <th>GENE_PCA_16</th>\n",
       "      <th>GENE_PCA_17</th>\n",
       "      <th>GENE_PCA_18</th>\n",
       "      <th>GENE_PCA_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7.6</td>\n",
       "      <td>119.0</td>\n",
       "      <td>False</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362127</td>\n",
       "      <td>-0.098401</td>\n",
       "      <td>-0.334633</td>\n",
       "      <td>-0.422827</td>\n",
       "      <td>0.406305</td>\n",
       "      <td>0.153874</td>\n",
       "      <td>-0.391967</td>\n",
       "      <td>0.182757</td>\n",
       "      <td>0.236527</td>\n",
       "      <td>0.202842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>11.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080871</td>\n",
       "      <td>-0.177629</td>\n",
       "      <td>-0.204931</td>\n",
       "      <td>-0.232519</td>\n",
       "      <td>0.062835</td>\n",
       "      <td>0.146025</td>\n",
       "      <td>0.089539</td>\n",
       "      <td>-0.028232</td>\n",
       "      <td>-0.337980</td>\n",
       "      <td>0.019597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.10</td>\n",
       "      <td>14.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355818</td>\n",
       "      <td>-0.136760</td>\n",
       "      <td>0.207136</td>\n",
       "      <td>0.501284</td>\n",
       "      <td>-0.258472</td>\n",
       "      <td>-0.428289</td>\n",
       "      <td>-0.346950</td>\n",
       "      <td>-0.213499</td>\n",
       "      <td>0.101130</td>\n",
       "      <td>0.047094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.90</td>\n",
       "      <td>8.9</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298820</td>\n",
       "      <td>-0.491564</td>\n",
       "      <td>0.371567</td>\n",
       "      <td>1.334935</td>\n",
       "      <td>-1.161551</td>\n",
       "      <td>-0.877461</td>\n",
       "      <td>-0.589696</td>\n",
       "      <td>0.042594</td>\n",
       "      <td>0.547192</td>\n",
       "      <td>-0.025505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>128.00</td>\n",
       "      <td>9.70</td>\n",
       "      <td>11.1</td>\n",
       "      <td>195.0</td>\n",
       "      <td>False</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097110</td>\n",
       "      <td>-0.185439</td>\n",
       "      <td>-0.043895</td>\n",
       "      <td>-0.159814</td>\n",
       "      <td>-0.011856</td>\n",
       "      <td>0.045029</td>\n",
       "      <td>0.104480</td>\n",
       "      <td>-0.078675</td>\n",
       "      <td>-0.295712</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.02</td>\n",
       "      <td>10.2</td>\n",
       "      <td>78.0</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019895</td>\n",
       "      <td>-0.122375</td>\n",
       "      <td>-0.222443</td>\n",
       "      <td>-0.034158</td>\n",
       "      <td>0.101435</td>\n",
       "      <td>0.191833</td>\n",
       "      <td>-0.082066</td>\n",
       "      <td>-0.023210</td>\n",
       "      <td>-0.074848</td>\n",
       "      <td>-0.465893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>1.5</td>\n",
       "      <td>8.10</td>\n",
       "      <td>2.66</td>\n",
       "      <td>11.3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>-0.023434</td>\n",
       "      <td>-0.058662</td>\n",
       "      <td>-0.036904</td>\n",
       "      <td>-0.024066</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>0.051518</td>\n",
       "      <td>-0.037426</td>\n",
       "      <td>-0.080861</td>\n",
       "      <td>0.006692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>False</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374401</td>\n",
       "      <td>0.517249</td>\n",
       "      <td>-0.545983</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.026998</td>\n",
       "      <td>0.030135</td>\n",
       "      <td>-0.207101</td>\n",
       "      <td>-0.200459</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.150896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>11.4</td>\n",
       "      <td>102.0</td>\n",
       "      <td>False</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613928</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.106959</td>\n",
       "      <td>-0.327796</td>\n",
       "      <td>0.161075</td>\n",
       "      <td>0.119511</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>-0.086212</td>\n",
       "      <td>-0.093364</td>\n",
       "      <td>0.063722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>8.2</td>\n",
       "      <td>239.0</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251653</td>\n",
       "      <td>-0.184903</td>\n",
       "      <td>0.040422</td>\n",
       "      <td>0.132461</td>\n",
       "      <td>-0.104562</td>\n",
       "      <td>-0.167681</td>\n",
       "      <td>-0.352788</td>\n",
       "      <td>-0.288971</td>\n",
       "      <td>-0.154754</td>\n",
       "      <td>0.082680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3173 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BM_BLAST     WBC   ANC    HB    PLT  is_normal  ploidy  \\\n",
       "0         14.0    2.80  0.20   7.6  119.0      False      46   \n",
       "1          1.0    7.40  2.40  11.6   42.0       True      46   \n",
       "2         15.0    3.70  2.10  14.2   81.0      False      46   \n",
       "3          1.0    3.90  1.90   8.9   77.0      False      46   \n",
       "4          6.0  128.00  9.70  11.1  195.0      False      46   \n",
       "...        ...     ...   ...   ...    ...        ...     ...   \n",
       "3168       1.0    2.50  1.02  10.2   78.0       True      46   \n",
       "3169       1.5    8.10  2.66  11.3   40.0      False      44   \n",
       "3170       0.0    1.80  0.55   9.4   86.0      False      45   \n",
       "3171       5.0    1.37  0.37  11.4  102.0      False      46   \n",
       "3172       0.0    2.70  0.72   8.2  239.0       True      46   \n",
       "\n",
       "      has_tp53_deletion  has_complex_chr3  n_abnormalities  ...  GENE_PCA_10  \\\n",
       "0                 False             False                1  ...    -0.362127   \n",
       "1                 False             False                0  ...    -0.080871   \n",
       "2                 False              True                1  ...     0.355818   \n",
       "3                 False             False                1  ...     1.298820   \n",
       "4                 False             False                1  ...    -0.097110   \n",
       "...                 ...               ...              ...  ...          ...   \n",
       "3168              False             False                0  ...     0.019895   \n",
       "3169              False             False                4  ...     0.005912   \n",
       "3170              False             False                1  ...    -0.374401   \n",
       "3171              False             False                1  ...     0.613928   \n",
       "3172              False             False                0  ...     0.251653   \n",
       "\n",
       "      GENE_PCA_11  GENE_PCA_12  GENE_PCA_13  GENE_PCA_14  GENE_PCA_15  \\\n",
       "0       -0.098401    -0.334633    -0.422827     0.406305     0.153874   \n",
       "1       -0.177629    -0.204931    -0.232519     0.062835     0.146025   \n",
       "2       -0.136760     0.207136     0.501284    -0.258472    -0.428289   \n",
       "3       -0.491564     0.371567     1.334935    -1.161551    -0.877461   \n",
       "4       -0.185439    -0.043895    -0.159814    -0.011856     0.045029   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3168    -0.122375    -0.222443    -0.034158     0.101435     0.191833   \n",
       "3169    -0.023434    -0.058662    -0.036904    -0.024066    -0.001572   \n",
       "3170     0.517249    -0.545983     0.003789     0.026998     0.030135   \n",
       "3171     0.029560     0.106959    -0.327796     0.161075     0.119511   \n",
       "3172    -0.184903     0.040422     0.132461    -0.104562    -0.167681   \n",
       "\n",
       "      GENE_PCA_16  GENE_PCA_17  GENE_PCA_18  GENE_PCA_19  \n",
       "0       -0.391967     0.182757     0.236527     0.202842  \n",
       "1        0.089539    -0.028232    -0.337980     0.019597  \n",
       "2       -0.346950    -0.213499     0.101130     0.047094  \n",
       "3       -0.589696     0.042594     0.547192    -0.025505  \n",
       "4        0.104480    -0.078675    -0.295712     0.004032  \n",
       "...           ...          ...          ...          ...  \n",
       "3168    -0.082066    -0.023210    -0.074848    -0.465893  \n",
       "3169     0.051518    -0.037426    -0.080861     0.006692  \n",
       "3170    -0.207101    -0.200459     0.427083     0.150896  \n",
       "3171     0.009930    -0.086212    -0.093364     0.063722  \n",
       "3172    -0.352788    -0.288971    -0.154754     0.082680  \n",
       "\n",
       "[3173 rows x 56 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff6f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE IMPORTANCE PRETRAINING\n",
      "============================================================\n",
      "\n",
      "--- Classification Feature Importance ---\n",
      "Computing tree-based feature importance...\n",
      "  Optimizing RF...\n",
      "  Optimizing XGB...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 3: FEATURE IMPORTANCE PRETRAINING\n",
    "# =============================================================================\n",
    "# Analyse feature importance avec random feature baseline\n",
    "# Sélectionne uniquement les features significatives\n",
    "# =============================================================================\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ens_data_challenge.training import (\n",
    "    analyze_feature_importance,\n",
    "    plot_feature_importance,\n",
    "    select_features,\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE IMPORTANCE PRETRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Classification task - P(event=1)\n",
    "print(\"\\n--- Classification Feature Importance ---\")\n",
    "fi_clf = analyze_feature_importance(\n",
    "    X_clinical,\n",
    "    events,\n",
    "    is_classifier=True,\n",
    "    threshold_method=\"random\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "y_transformed = transform_y(y_times)\n",
    "\n",
    "print(\"\\n--- Regression Feature Importance ---\")\n",
    "fi_reg = analyze_feature_importance(\n",
    "    X_clinical,\n",
    "    y_transformed,\n",
    "    is_classifier=False,\n",
    "    threshold_method=\"random\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Keep features significant in BOTH classification AND regression\n",
    "selected_clf = set(fi_clf.selected_features)\n",
    "selected_reg = set(fi_reg.selected_features)\n",
    "final_selected = list(\n",
    "    selected_clf | selected_reg\n",
    ")  # Union pour garder les features importants\n",
    "\n",
    "# Log dropped features\n",
    "dropped_features = [f for f in X_clinical.columns if f not in final_selected]\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"FINAL FEATURE SELECTION\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Original features: {len(X_clinical.columns)}\")\n",
    "print(f\"Selected features: {len(final_selected)}\")\n",
    "print(f\"Dropped features: {len(dropped_features)}\")\n",
    "print(\n",
    "    f\"\\nDropped: {dropped_features[:20]}...\"\n",
    "    if len(dropped_features) > 20\n",
    "    else f\"\\nDropped: {dropped_features}\"\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig_clf = plot_feature_importance(fi_clf, top_n=25)\n",
    "fig_clf.suptitle(\"Classification Feature Importance\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "fig_reg = plot_feature_importance(fi_reg, top_n=25)\n",
    "fig_reg.suptitle(\"Regression Feature Importance\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Apply selection\n",
    "X_clinical_selected = select_features(X_clinical, final_selected)\n",
    "print(f\"\\nX_clinical after selection: {X_clinical_selected.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf563048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLASSIFICATION: P(event=1)\n",
      "============================================================\n",
      "\n",
      "--- XGB ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: -0.678517: 100%|██████████| 30/30 [01:07<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: AUC=0.7159, IPCW_C=0.7049\n",
      "  Fold 2: AUC=0.7099, IPCW_C=0.6429\n",
      "  Fold 3: AUC=0.7075, IPCW_C=0.6679\n",
      "  Fold 4: AUC=0.7029, IPCW_C=0.6875\n",
      "  Fold 5: AUC=0.6711, IPCW_C=0.6475\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=-0.7305, val_loss=-0.7159, ipcw_c=0.7049\n",
      "Fold 1: train_loss=-0.7310, val_loss=-0.7099, ipcw_c=0.6429\n",
      "Fold 2: train_loss=-0.7314, val_loss=-0.7075, ipcw_c=0.6679\n",
      "Fold 3: train_loss=-0.7312, val_loss=-0.7029, ipcw_c=0.6875\n",
      "Fold 4: train_loss=-0.7307, val_loss=-0.6711, ipcw_c=0.6475\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: -0.7309\n",
      "Mean Val Loss:   -0.7015\n",
      "Mean IPCW C-idx: 0.6701 ± 0.0235\n",
      "Mean AUC:        0.7015\n",
      "============================================================\n",
      "\n",
      "--- LGBM ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: -0.642907: 100%|██████████| 30/30 [01:09<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: AUC=0.6755, IPCW_C=0.6779\n",
      "  Fold 2: AUC=0.6936, IPCW_C=0.6024\n",
      "  Fold 3: AUC=0.6651, IPCW_C=0.6410\n",
      "  Fold 4: AUC=0.6895, IPCW_C=0.6598\n",
      "  Fold 5: AUC=0.6810, IPCW_C=0.6548\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=-0.7169, val_loss=-0.6755, ipcw_c=0.6779\n",
      "Fold 1: train_loss=-0.7151, val_loss=-0.6936, ipcw_c=0.6024\n",
      "Fold 2: train_loss=-0.7290, val_loss=-0.6651, ipcw_c=0.6410\n",
      "Fold 3: train_loss=-0.7191, val_loss=-0.6895, ipcw_c=0.6598\n",
      "Fold 4: train_loss=-0.7251, val_loss=-0.6810, ipcw_c=0.6548\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: -0.7210\n",
      "Mean Val Loss:   -0.6809\n",
      "Mean IPCW C-idx: 0.6472 ± 0.0253\n",
      "Mean AUC:        0.6809\n",
      "============================================================\n",
      "\n",
      "--- CatBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: -0.660697: 100%|██████████| 30/30 [02:27<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: AUC=0.7318, IPCW_C=0.7209\n",
      "  Fold 2: AUC=0.7083, IPCW_C=0.6619\n",
      "  Fold 3: AUC=0.7015, IPCW_C=0.6626\n",
      "  Fold 4: AUC=0.7194, IPCW_C=0.6938\n",
      "  Fold 5: AUC=0.7001, IPCW_C=0.6743\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=-0.7227, val_loss=-0.7318, ipcw_c=0.7209\n",
      "Fold 1: train_loss=-0.7259, val_loss=-0.7083, ipcw_c=0.6619\n",
      "Fold 2: train_loss=-0.7258, val_loss=-0.7015, ipcw_c=0.6626\n",
      "Fold 3: train_loss=-0.7291, val_loss=-0.7194, ipcw_c=0.6938\n",
      "Fold 4: train_loss=-0.7335, val_loss=-0.7001, ipcw_c=0.6743\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: -0.7274\n",
      "Mean Val Loss:   -0.7122\n",
      "Mean IPCW C-idx: 0.6827 ± 0.0223\n",
      "Mean AUC:        0.7122\n",
      "============================================================\n",
      "\n",
      "--- RF ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: -0.491762: 100%|██████████| 30/30 [04:23<00:00,  8.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: AUC=0.6871, IPCW_C=0.6720\n",
      "  Fold 2: AUC=0.6777, IPCW_C=0.6026\n",
      "  Fold 3: AUC=0.6884, IPCW_C=0.6546\n",
      "  Fold 4: AUC=0.7141, IPCW_C=0.6905\n",
      "  Fold 5: AUC=0.6987, IPCW_C=0.6686\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=-0.6891, val_loss=-0.6871, ipcw_c=0.6720\n",
      "Fold 1: train_loss=-0.7073, val_loss=-0.6777, ipcw_c=0.6026\n",
      "Fold 2: train_loss=-0.7079, val_loss=-0.6884, ipcw_c=0.6546\n",
      "Fold 3: train_loss=-0.7142, val_loss=-0.7141, ipcw_c=0.6905\n",
      "Fold 4: train_loss=-0.7191, val_loss=-0.6987, ipcw_c=0.6686\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: -0.7075\n",
      "Mean Val Loss:   -0.6932\n",
      "Mean IPCW C-idx: 0.6577 ± 0.0298\n",
      "Mean AUC:        0.6932\n",
      "============================================================\n",
      "\n",
      "--- LR ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: -0.724264: 100%|██████████| 30/30 [00:26<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: AUC=0.7141, IPCW_C=0.7034\n",
      "  Fold 2: AUC=0.7328, IPCW_C=0.6528\n",
      "  Fold 3: AUC=0.7332, IPCW_C=0.6865\n",
      "  Fold 4: AUC=0.7168, IPCW_C=0.7027\n",
      "  Fold 5: AUC=0.7325, IPCW_C=0.7063\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=-0.7447, val_loss=-0.7141, ipcw_c=0.7034\n",
      "Fold 1: train_loss=-0.7385, val_loss=-0.7328, ipcw_c=0.6528\n",
      "Fold 2: train_loss=-0.7406, val_loss=-0.7332, ipcw_c=0.6865\n",
      "Fold 3: train_loss=-0.7454, val_loss=-0.7168, ipcw_c=0.7027\n",
      "Fold 4: train_loss=-0.7400, val_loss=-0.7325, ipcw_c=0.7063\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: -0.7418\n",
      "Mean Val Loss:   -0.7259\n",
      "Mean IPCW C-idx: 0.6904 ± 0.0200\n",
      "Mean AUC:        0.7259\n",
      "============================================================\n",
      "\n",
      "--- LDA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: -0.714426: 100%|██████████| 30/30 [00:22<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: AUC=0.7146, IPCW_C=0.7038\n",
      "  Fold 2: AUC=0.7326, IPCW_C=0.6527\n",
      "  Fold 3: AUC=0.7326, IPCW_C=0.6858\n",
      "  Fold 4: AUC=0.7179, IPCW_C=0.7037\n",
      "  Fold 5: AUC=0.7320, IPCW_C=0.7055\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=-0.7438, val_loss=-0.7146, ipcw_c=0.7038\n",
      "Fold 1: train_loss=-0.7375, val_loss=-0.7326, ipcw_c=0.6527\n",
      "Fold 2: train_loss=-0.7396, val_loss=-0.7326, ipcw_c=0.6858\n",
      "Fold 3: train_loss=-0.7442, val_loss=-0.7179, ipcw_c=0.7037\n",
      "Fold 4: train_loss=-0.7393, val_loss=-0.7320, ipcw_c=0.7055\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: -0.7409\n",
      "Mean Val Loss:   -0.7259\n",
      "Mean IPCW C-idx: 0.6903 ± 0.0201\n",
      "Mean AUC:        0.7259\n",
      "============================================================\n",
      "\n",
      "--- QDA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: -0.703105: 100%|██████████| 30/30 [00:55<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: AUC=0.6928, IPCW_C=0.6884\n",
      "  Fold 2: AUC=0.7192, IPCW_C=0.6285\n",
      "  Fold 3: AUC=0.7194, IPCW_C=0.6742\n",
      "  Fold 4: AUC=0.7180, IPCW_C=0.7010\n",
      "  Fold 5: AUC=0.7239, IPCW_C=0.6978\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=-0.7340, val_loss=-0.6928, ipcw_c=0.6884\n",
      "Fold 1: train_loss=-0.7266, val_loss=-0.7192, ipcw_c=0.6285\n",
      "Fold 2: train_loss=-0.7287, val_loss=-0.7194, ipcw_c=0.6742\n",
      "Fold 3: train_loss=-0.7325, val_loss=-0.7180, ipcw_c=0.7010\n",
      "Fold 4: train_loss=-0.7296, val_loss=-0.7239, ipcw_c=0.6978\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: -0.7303\n",
      "Mean Val Loss:   -0.7147\n",
      "Mean IPCW C-idx: 0.6780 ± 0.0264\n",
      "Mean AUC:        0.7147\n",
      "============================================================\n",
      "\n",
      "--- LinearSVC ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: -0.714128: 100%|██████████| 30/30 [01:15<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: AUC=0.7142, IPCW_C=0.7031\n",
      "  Fold 2: AUC=0.7328, IPCW_C=0.6529\n",
      "  Fold 3: AUC=0.7325, IPCW_C=0.6859\n",
      "  Fold 4: AUC=0.7171, IPCW_C=0.7031\n",
      "  Fold 5: AUC=0.7320, IPCW_C=0.7058\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=-0.7445, val_loss=-0.7142, ipcw_c=0.7031\n",
      "Fold 1: train_loss=-0.7383, val_loss=-0.7328, ipcw_c=0.6529\n",
      "Fold 2: train_loss=-0.7403, val_loss=-0.7325, ipcw_c=0.6859\n",
      "Fold 3: train_loss=-0.7451, val_loss=-0.7171, ipcw_c=0.7031\n",
      "Fold 4: train_loss=-0.7400, val_loss=-0.7320, ipcw_c=0.7058\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: -0.7416\n",
      "Mean Val Loss:   -0.7257\n",
      "Mean IPCW C-idx: 0.6902 ± 0.0199\n",
      "Mean AUC:        0.7257\n",
      "============================================================\n",
      "\n",
      "--- ElasticNetLR ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: -0.719176: 100%|██████████| 30/30 [04:21<00:00,  8.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: AUC=0.7081, IPCW_C=0.6962\n",
      "  Fold 2: AUC=0.7325, IPCW_C=0.6560\n",
      "  Fold 3: AUC=0.7328, IPCW_C=0.6887\n",
      "  Fold 4: AUC=0.7088, IPCW_C=0.6979\n",
      "  Fold 5: AUC=0.7273, IPCW_C=0.7024\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=-0.7485, val_loss=-0.7081, ipcw_c=0.6962\n",
      "Fold 1: train_loss=-0.7419, val_loss=-0.7325, ipcw_c=0.6560\n",
      "Fold 2: train_loss=-0.7442, val_loss=-0.7328, ipcw_c=0.6887\n",
      "Fold 3: train_loss=-0.7495, val_loss=-0.7088, ipcw_c=0.6979\n",
      "Fold 4: train_loss=-0.7427, val_loss=-0.7273, ipcw_c=0.7024\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: -0.7454\n",
      "Mean Val Loss:   -0.7219\n",
      "Mean IPCW C-idx: 0.6882 ± 0.0167\n",
      "Mean AUC:        0.7219\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ENSEMBLE P(event=1)\n",
      "  Ensemble IPCW C-index: 0.6953\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 3: CLASSIFICATION - P(event=1)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CLASSIFICATION: P(event=1)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "clf_results = {}\n",
    "\n",
    "for model_name in CLF_MODELS:\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    oof, models, cv_results, params = train_classifier_cv(\n",
    "        X_clinical_selected,\n",
    "        events,\n",
    "        y_times,\n",
    "        events,\n",
    "        model_name,\n",
    "        n_folds=N_FOLDS,\n",
    "        n_trials=N_TRIALS,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    clf_results[model_name] = {\n",
    "        \"oof\": oof,\n",
    "        \"models\": models,\n",
    "        \"cv_results\": cv_results,\n",
    "        \"params\": params,\n",
    "    }\n",
    "\n",
    "# Ensemble\n",
    "oof_proba = np.mean([r[\"oof\"] for r in clf_results.values()], axis=0)\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"ENSEMBLE P(event=1)\")\n",
    "final_auc = compute_ipcw_cindex(y_times, events, y_times, events, oof_proba)\n",
    "print(f\"  Ensemble IPCW C-index: {final_auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3447a3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REGRESSION: E[rank|event=1] (trained on events only)\n",
      "============================================================\n",
      "\n",
      "--- XGB ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.0899913: 100%|██████████| 30/30 [00:14<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0840, IPCW_C=0.5967\n",
      "  Fold 2: MSE=0.0842, IPCW_C=0.5786\n",
      "  Fold 3: MSE=0.0840, IPCW_C=0.6048\n",
      "  Fold 4: MSE=0.0841, IPCW_C=0.5843\n",
      "  Fold 5: MSE=0.0841, IPCW_C=0.5846\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0842, val_loss=0.0840, ipcw_c=0.5967\n",
      "Fold 1: train_loss=0.0843, val_loss=0.0842, ipcw_c=0.5786\n",
      "Fold 2: train_loss=0.0842, val_loss=0.0840, ipcw_c=0.6048\n",
      "Fold 3: train_loss=0.0843, val_loss=0.0841, ipcw_c=0.5843\n",
      "Fold 4: train_loss=0.0842, val_loss=0.0841, ipcw_c=0.5846\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0842\n",
      "Mean Val Loss:   0.0841\n",
      "Mean IPCW C-idx: 0.5898 ± 0.0096\n",
      "============================================================\n",
      "\n",
      "--- LGBM ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.114795: 100%|██████████| 30/30 [00:30<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0838, IPCW_C=0.5795\n",
      "  Fold 2: MSE=0.0840, IPCW_C=0.5497\n",
      "  Fold 3: MSE=0.0837, IPCW_C=0.5796\n",
      "  Fold 4: MSE=0.0839, IPCW_C=0.5673\n",
      "  Fold 5: MSE=0.0841, IPCW_C=0.5637\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0839, val_loss=0.0838, ipcw_c=0.5795\n",
      "Fold 1: train_loss=0.0840, val_loss=0.0840, ipcw_c=0.5497\n",
      "Fold 2: train_loss=0.0840, val_loss=0.0837, ipcw_c=0.5796\n",
      "Fold 3: train_loss=0.0840, val_loss=0.0839, ipcw_c=0.5673\n",
      "Fold 4: train_loss=0.0839, val_loss=0.0841, ipcw_c=0.5637\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0840\n",
      "Mean Val Loss:   0.0839\n",
      "Mean IPCW C-idx: 0.5680 ± 0.0112\n",
      "============================================================\n",
      "\n",
      "--- CatBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.089471: 100%|██████████| 30/30 [01:44<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0836, IPCW_C=0.5972\n",
      "  Fold 2: MSE=0.0836, IPCW_C=0.5814\n",
      "  Fold 3: MSE=0.0833, IPCW_C=0.6100\n",
      "  Fold 4: MSE=0.0837, IPCW_C=0.5834\n",
      "  Fold 5: MSE=0.0836, IPCW_C=0.6076\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0837, val_loss=0.0836, ipcw_c=0.5972\n",
      "Fold 1: train_loss=0.0836, val_loss=0.0836, ipcw_c=0.5814\n",
      "Fold 2: train_loss=0.0837, val_loss=0.0833, ipcw_c=0.6100\n",
      "Fold 3: train_loss=0.0837, val_loss=0.0837, ipcw_c=0.5834\n",
      "Fold 4: train_loss=0.0837, val_loss=0.0836, ipcw_c=0.6076\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0837\n",
      "Mean Val Loss:   0.0836\n",
      "Mean IPCW C-idx: 0.5959 ± 0.0119\n",
      "============================================================\n",
      "\n",
      "--- Ridge ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.0769765: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0750, IPCW_C=0.6849\n",
      "  Fold 2: MSE=0.0762, IPCW_C=0.6683\n",
      "  Fold 3: MSE=0.0710, IPCW_C=0.6985\n",
      "  Fold 4: MSE=0.0708, IPCW_C=0.6859\n",
      "  Fold 5: MSE=0.0777, IPCW_C=0.6860\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0721, val_loss=0.0750, ipcw_c=0.6849\n",
      "Fold 1: train_loss=0.0719, val_loss=0.0762, ipcw_c=0.6683\n",
      "Fold 2: train_loss=0.0726, val_loss=0.0710, ipcw_c=0.6985\n",
      "Fold 3: train_loss=0.0736, val_loss=0.0708, ipcw_c=0.6859\n",
      "Fold 4: train_loss=0.0756, val_loss=0.0777, ipcw_c=0.6860\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0732\n",
      "Mean Val Loss:   0.0741\n",
      "Mean IPCW C-idx: 0.6847 ± 0.0096\n",
      "============================================================\n",
      "\n",
      "--- ElasticNet ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.0872937: 100%|██████████| 30/30 [00:12<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0844, IPCW_C=0.5000\n",
      "  Fold 2: MSE=0.0845, IPCW_C=0.5000\n",
      "  Fold 3: MSE=0.0844, IPCW_C=0.5000\n",
      "  Fold 4: MSE=0.0845, IPCW_C=0.5000\n",
      "  Fold 5: MSE=0.0844, IPCW_C=0.5000\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0846, val_loss=0.0844, ipcw_c=0.5000\n",
      "Fold 1: train_loss=0.0847, val_loss=0.0845, ipcw_c=0.5000\n",
      "Fold 2: train_loss=0.0846, val_loss=0.0844, ipcw_c=0.5000\n",
      "Fold 3: train_loss=0.0847, val_loss=0.0845, ipcw_c=0.5000\n",
      "Fold 4: train_loss=0.0846, val_loss=0.0844, ipcw_c=0.5000\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0846\n",
      "Mean Val Loss:   0.0844\n",
      "Mean IPCW C-idx: 0.5000 ± 0.0000\n",
      "============================================================\n",
      "\n",
      "--- PLS ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.0874168: 100%|██████████| 30/30 [00:12<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0759, IPCW_C=0.6646\n",
      "  Fold 2: MSE=0.0759, IPCW_C=0.6463\n",
      "  Fold 3: MSE=0.0729, IPCW_C=0.6770\n",
      "  Fold 4: MSE=0.0737, IPCW_C=0.6677\n",
      "  Fold 5: MSE=0.0775, IPCW_C=0.6616\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0746, val_loss=0.0759, ipcw_c=0.6646\n",
      "Fold 1: train_loss=0.0745, val_loss=0.0759, ipcw_c=0.6463\n",
      "Fold 2: train_loss=0.0751, val_loss=0.0729, ipcw_c=0.6770\n",
      "Fold 3: train_loss=0.0751, val_loss=0.0737, ipcw_c=0.6677\n",
      "Fold 4: train_loss=0.0757, val_loss=0.0775, ipcw_c=0.6616\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0750\n",
      "Mean Val Loss:   0.0752\n",
      "Mean IPCW C-idx: 0.6634 ± 0.0100\n",
      "============================================================\n",
      "\n",
      "--- KernelRidge ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.0798147: 100%|██████████| 30/30 [02:28<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0726, IPCW_C=0.6809\n",
      "  Fold 2: MSE=0.0750, IPCW_C=0.6649\n",
      "  Fold 3: MSE=0.0734, IPCW_C=0.6945\n",
      "  Fold 4: MSE=0.0723, IPCW_C=0.6864\n",
      "  Fold 5: MSE=0.0759, IPCW_C=0.6850\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0739, val_loss=0.0726, ipcw_c=0.6809\n",
      "Fold 1: train_loss=0.0731, val_loss=0.0750, ipcw_c=0.6649\n",
      "Fold 2: train_loss=0.0734, val_loss=0.0734, ipcw_c=0.6945\n",
      "Fold 3: train_loss=0.0735, val_loss=0.0723, ipcw_c=0.6864\n",
      "Fold 4: train_loss=0.0725, val_loss=0.0759, ipcw_c=0.6850\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0733\n",
      "Mean Val Loss:   0.0739\n",
      "Mean IPCW C-idx: 0.6824 ± 0.0098\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 4: REGRESSION - E[rank|event=1]\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REGRESSION: E[rank|event=1] (trained on events only)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "e1_mask = events == 1\n",
    "reg_e1_results = {}\n",
    "\n",
    "for model_name in REG_MODELS:\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    oof, models, cv_results, params = train_regressor_cv(\n",
    "        X_clinical_selected,\n",
    "        y_times,\n",
    "        events,\n",
    "        model_name,\n",
    "        subset_mask=e1_mask,\n",
    "        n_folds=N_FOLDS,\n",
    "        n_trials=N_TRIALS,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    reg_e1_results[model_name] = {\n",
    "        \"oof\": oof,\n",
    "        \"models\": models,\n",
    "        \"cv_results\": cv_results,\n",
    "        \"params\": params,\n",
    "    }\n",
    "\n",
    "oof_rank_e1 = np.mean([r[\"oof\"] for r in reg_e1_results.values()], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf4e94",
   "metadata": {},
   "source": [
    "pour ca on ft un optimal ensemble avec optuna plutot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066820a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REGRESSION: E[rank|event=0] (trained on censored only)\n",
      "============================================================\n",
      "\n",
      "--- XGB ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.0875578: 100%|██████████| 30/30 [00:11<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0844, IPCW_C=0.5167\n",
      "  Fold 2: MSE=0.0839, IPCW_C=0.5384\n",
      "  Fold 3: MSE=0.0840, IPCW_C=0.5467\n",
      "  Fold 4: MSE=0.0842, IPCW_C=0.5477\n",
      "  Fold 5: MSE=0.0843, IPCW_C=0.5585\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0841, val_loss=0.0844, ipcw_c=0.5167\n",
      "Fold 1: train_loss=0.0838, val_loss=0.0839, ipcw_c=0.5384\n",
      "Fold 2: train_loss=0.0842, val_loss=0.0840, ipcw_c=0.5467\n",
      "Fold 3: train_loss=0.0844, val_loss=0.0842, ipcw_c=0.5477\n",
      "Fold 4: train_loss=0.0842, val_loss=0.0843, ipcw_c=0.5585\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0841\n",
      "Mean Val Loss:   0.0842\n",
      "Mean IPCW C-idx: 0.5416 ± 0.0140\n",
      "============================================================\n",
      "\n",
      "--- LGBM ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.10569: 100%|██████████| 30/30 [00:07<00:00,  4.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0842, IPCW_C=0.6102\n",
      "  Fold 2: MSE=0.0843, IPCW_C=0.5891\n",
      "  Fold 3: MSE=0.0842, IPCW_C=0.6300\n",
      "  Fold 4: MSE=0.0844, IPCW_C=0.6310\n",
      "  Fold 5: MSE=0.0844, IPCW_C=0.6084\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0844, val_loss=0.0842, ipcw_c=0.6102\n",
      "Fold 1: train_loss=0.0844, val_loss=0.0843, ipcw_c=0.5891\n",
      "Fold 2: train_loss=0.0844, val_loss=0.0842, ipcw_c=0.6300\n",
      "Fold 3: train_loss=0.0846, val_loss=0.0844, ipcw_c=0.6310\n",
      "Fold 4: train_loss=0.0845, val_loss=0.0844, ipcw_c=0.6084\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0845\n",
      "Mean Val Loss:   0.0843\n",
      "Mean IPCW C-idx: 0.6137 ± 0.0156\n",
      "============================================================\n",
      "\n",
      "--- CatBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.0877715: 100%|██████████| 30/30 [00:21<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0843, IPCW_C=0.5511\n",
      "  Fold 2: MSE=0.0843, IPCW_C=0.5443\n",
      "  Fold 3: MSE=0.0843, IPCW_C=0.5474\n",
      "  Fold 4: MSE=0.0845, IPCW_C=0.5489\n",
      "  Fold 5: MSE=0.0845, IPCW_C=0.5585\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0845, val_loss=0.0843, ipcw_c=0.5511\n",
      "Fold 1: train_loss=0.0845, val_loss=0.0843, ipcw_c=0.5443\n",
      "Fold 2: train_loss=0.0845, val_loss=0.0843, ipcw_c=0.5474\n",
      "Fold 3: train_loss=0.0846, val_loss=0.0845, ipcw_c=0.5489\n",
      "Fold 4: train_loss=0.0846, val_loss=0.0845, ipcw_c=0.5585\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0845\n",
      "Mean Val Loss:   0.0844\n",
      "Mean IPCW C-idx: 0.5500 ± 0.0048\n",
      "============================================================\n",
      "\n",
      "--- Ridge ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.0794815: 100%|██████████| 30/30 [00:02<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0732, IPCW_C=0.6690\n",
      "  Fold 2: MSE=0.0787, IPCW_C=0.6371\n",
      "  Fold 3: MSE=0.0897, IPCW_C=0.6907\n",
      "  Fold 4: MSE=0.0744, IPCW_C=0.6783\n",
      "  Fold 5: MSE=0.0758, IPCW_C=0.7108\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0730, val_loss=0.0732, ipcw_c=0.6690\n",
      "Fold 1: train_loss=0.0729, val_loss=0.0787, ipcw_c=0.6371\n",
      "Fold 2: train_loss=0.0738, val_loss=0.0897, ipcw_c=0.6907\n",
      "Fold 3: train_loss=0.0730, val_loss=0.0744, ipcw_c=0.6783\n",
      "Fold 4: train_loss=0.0712, val_loss=0.0758, ipcw_c=0.7108\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0728\n",
      "Mean Val Loss:   0.0784\n",
      "Mean IPCW C-idx: 0.6772 ± 0.0244\n",
      "============================================================\n",
      "\n",
      "--- ElasticNet ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 0.0849799: 100%|██████████| 30/30 [00:03<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0815, IPCW_C=0.6131\n",
      "  Fold 2: MSE=0.0812, IPCW_C=0.5945\n",
      "  Fold 3: MSE=0.0800, IPCW_C=0.6288\n",
      "  Fold 4: MSE=0.0808, IPCW_C=0.6204\n",
      "  Fold 5: MSE=0.0833, IPCW_C=0.5958\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0819, val_loss=0.0815, ipcw_c=0.6131\n",
      "Fold 1: train_loss=0.0797, val_loss=0.0812, ipcw_c=0.5945\n",
      "Fold 2: train_loss=0.0810, val_loss=0.0800, ipcw_c=0.6288\n",
      "Fold 3: train_loss=0.0812, val_loss=0.0808, ipcw_c=0.6204\n",
      "Fold 4: train_loss=0.0819, val_loss=0.0833, ipcw_c=0.5958\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0811\n",
      "Mean Val Loss:   0.0814\n",
      "Mean IPCW C-idx: 0.6105 ± 0.0135\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 5: REGRESSION - E[rank|event=0]\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REGRESSION: E[rank|event=0] (trained on censored only)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "e0_mask = events == 0\n",
    "reg_e0_results = {}\n",
    "\n",
    "for model_name in REG_MODELS:\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    oof, models, cv_results, params = train_regressor_cv(\n",
    "        X_clinical_selected,\n",
    "        y_times,\n",
    "        events,\n",
    "        model_name,\n",
    "        subset_mask=e0_mask,\n",
    "        n_folds=N_FOLDS,\n",
    "        n_trials=N_TRIALS,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    reg_e0_results[model_name] = {\n",
    "        \"oof\": oof,\n",
    "        \"models\": models,\n",
    "        \"cv_results\": cv_results,\n",
    "        \"params\": params,\n",
    "    }\n",
    "\n",
    "oof_rank_e0 = np.mean([r[\"oof\"] for r in reg_e0_results.values()], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5547e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REGRESSION: E[rank|IPCW] (trained with KM weights)\n",
      "============================================================\n",
      "\n",
      "--- XGB ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 25. Best value: 0.130347: 100%|██████████| 30/30 [01:23<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0909, IPCW_C=0.6409\n",
      "  Fold 2: MSE=0.0917, IPCW_C=0.6026\n",
      "  Fold 3: MSE=0.0864, IPCW_C=0.6519\n",
      "  Fold 4: MSE=0.0915, IPCW_C=0.6470\n",
      "  Fold 5: MSE=0.0909, IPCW_C=0.6402\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0915, val_loss=0.0909, ipcw_c=0.6409\n",
      "Fold 1: train_loss=0.0894, val_loss=0.0917, ipcw_c=0.6026\n",
      "Fold 2: train_loss=0.0887, val_loss=0.0864, ipcw_c=0.6519\n",
      "Fold 3: train_loss=0.0926, val_loss=0.0915, ipcw_c=0.6470\n",
      "Fold 4: train_loss=0.0871, val_loss=0.0909, ipcw_c=0.6402\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0899\n",
      "Mean Val Loss:   0.0903\n",
      "Mean IPCW C-idx: 0.6365 ± 0.0175\n",
      "============================================================\n",
      "\n",
      "--- LGBM ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.124406: 100%|██████████| 30/30 [01:44<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.0936, IPCW_C=0.6369\n",
      "  Fold 2: MSE=0.0927, IPCW_C=0.6324\n",
      "  Fold 3: MSE=0.0894, IPCW_C=0.6518\n",
      "  Fold 4: MSE=0.0976, IPCW_C=0.6398\n",
      "  Fold 5: MSE=0.0933, IPCW_C=0.6417\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.0937, val_loss=0.0936, ipcw_c=0.6369\n",
      "Fold 1: train_loss=0.0921, val_loss=0.0927, ipcw_c=0.6324\n",
      "Fold 2: train_loss=0.0896, val_loss=0.0894, ipcw_c=0.6518\n",
      "Fold 3: train_loss=0.0964, val_loss=0.0976, ipcw_c=0.6398\n",
      "Fold 4: train_loss=0.0906, val_loss=0.0933, ipcw_c=0.6417\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.0925\n",
      "Mean Val Loss:   0.0933\n",
      "Mean IPCW C-idx: 0.6405 ± 0.0065\n",
      "============================================================\n",
      "\n",
      "--- CatBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.102382: 100%|██████████| 30/30 [01:07<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: MSE=0.1011, IPCW_C=0.5298\n",
      "  Fold 2: MSE=0.1001, IPCW_C=0.5769\n",
      "  Fold 3: MSE=0.0962, IPCW_C=0.5879\n",
      "  Fold 4: MSE=0.1057, IPCW_C=0.5912\n",
      "  Fold 5: MSE=0.0987, IPCW_C=0.5881\n",
      "============================================================\n",
      "CV RESULTS SUMMARY\n",
      "============================================================\n",
      "Fold 0: train_loss=0.1013, val_loss=0.1011, ipcw_c=0.5298\n",
      "Fold 1: train_loss=0.1002, val_loss=0.1001, ipcw_c=0.5769\n",
      "Fold 2: train_loss=0.0964, val_loss=0.0962, ipcw_c=0.5879\n",
      "Fold 3: train_loss=0.1060, val_loss=0.1057, ipcw_c=0.5912\n",
      "Fold 4: train_loss=0.0988, val_loss=0.0987, ipcw_c=0.5881\n",
      "------------------------------------------------------------\n",
      "Mean Train Loss: 0.1006\n",
      "Mean Val Loss:   0.1004\n",
      "Mean IPCW C-idx: 0.5748 ± 0.0230\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 6: REGRESSION - E[rank|IPCW]\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REGRESSION: E[rank|IPCW] (trained with KM weights)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "reg_ipcw_results = {}\n",
    "\n",
    "for model_name in IPCW_MODELS:\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    oof, models, cv_results, params = train_regressor_cv(\n",
    "        X_clinical_selected,\n",
    "        y_times,\n",
    "        events,\n",
    "        model_name,\n",
    "        use_ipcw=True,\n",
    "        n_folds=N_FOLDS,\n",
    "        n_trials=N_TRIALS,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    reg_ipcw_results[model_name] = {\n",
    "        \"oof\": oof,\n",
    "        \"models\": models,\n",
    "        \"cv_results\": cv_results,\n",
    "        \"params\": params,\n",
    "    }\n",
    "\n",
    "oof_rank_ipcw = np.mean([r[\"oof\"] for r in reg_ipcw_results.values()], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71706656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CYTO STRUCT: CatBoost Classification\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2758, 3173]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     14\u001b[39m skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=RANDOM_STATE)\n\u001b[32m     16\u001b[39m oof_proba_cyto = np.zeros(\u001b[38;5;28mlen\u001b[39m(events))\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mskf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_cyto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_cyto\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_features\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_pool\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_cyto\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:401\u001b[39m, in \u001b[36m_BaseKFold.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, groups=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    378\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[32m    379\u001b[39m \n\u001b[32m    380\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    399\u001b[39m \u001b[33;03m        The testing set indices for that split.\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     X, y, groups = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m     n_samples = _num_samples(X)\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_splits > n_samples:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:530\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    501\u001b[39m \n\u001b[32m    502\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    529\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [2758, 3173]"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 7: CYTO STRUCT CLASSIFICATION (CatBoost avec cat_features)\n",
    "# =============================================================================\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CYTO STRUCT: CatBoost Classification\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cat_features = list(X_cyto.columns)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "oof_proba_cyto = np.zeros(len(events))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_cyto, events)):\n",
    "    train_pool = Pool(\n",
    "        X_cyto.iloc[train_idx], events[train_idx], cat_features=cat_features\n",
    "    )\n",
    "    val_pool = Pool(X_cyto.iloc[val_idx], events[val_idx], cat_features=cat_features)\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=200, depth=6, learning_rate=0.1, random_state=RANDOM_STATE, verbose=0\n",
    "    )\n",
    "    model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "    oof_proba_cyto[val_idx] = model.predict_proba(X_cyto.iloc[val_idx])[:, 1]\n",
    "\n",
    "    print(\n",
    "        f\"  Fold {fold + 1}: AUC={compute_ipcw_cindex(y_times[train_idx], events[train_idx], y_times[val_idx], events[val_idx], oof_proba_cyto[val_idx]):.4f}\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "META-FEATURES\n",
      "============================================================\n",
      "Meta-features: (3173, 93)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 8: META-FEATURES DATAFRAME\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"META-FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine features\n",
    "X_meta = X_clinical_selected.copy()\n",
    "\n",
    "# Predictions\n",
    "X_meta[\"prob_event1\"] = oof_proba\n",
    "X_meta[\"prob_event0\"] = 1 - oof_proba\n",
    "# X_meta[\"prob_cyto\"] = oof_proba_cyto\n",
    "X_meta[\"rank_e1\"] = scale_01(oof_rank_e1)\n",
    "X_meta[\"rank_e0\"] = scale_01(oof_rank_e0)\n",
    "X_meta[\"rank_ipcw\"] = scale_01(oof_rank_ipcw)\n",
    "\n",
    "# Polynomial features\n",
    "pred_cols = [\"prob_event1\", \"rank_e1\", \"rank_e0\", \"rank_ipcw\"]\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_feats = poly.fit_transform(X_meta[pred_cols].values)\n",
    "for i in range(poly_feats.shape[1]):\n",
    "    X_meta[f\"poly_{i}\"] = poly_feats[:, i]\n",
    "\n",
    "print(f\"Meta-features: {X_meta.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bae4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FORMULA OPTIMIZATION\n",
      "============================================================\n",
      "Rang = P(e=0)*w0*E[r|e=0] + P(e=1)*(w1_base + w1_rank*E[r|e=1]) + w_ipcw*E[IPCW]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 92. Best value: -0.704236: 100%|██████████| 100/100 [00:09<00:00, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params: {'w0': 0.9983081172559186, 'w1_base': 0.7989920462780471, 'w1_rank': 0.37038613369805823, 'w_ipcw': 0.948958288136958}\n",
      "Formula IPCW C-index: 0.7042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 9: FORMULA OPTIMIZATION\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FORMULA OPTIMIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\n",
    "    \"Rang = P(e=0)*w0*E[r|e=0] + P(e=1)*(w1_base + w1_rank*E[r|e=1]) + w_ipcw*E[IPCW]\"\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Prepare scaled values\n",
    "proba = oof_proba\n",
    "rank_e0 = scale_01(oof_rank_e0)\n",
    "rank_e1 = scale_01(oof_rank_e1)\n",
    "rank_ipcw = scale_01(oof_rank_ipcw)\n",
    "\n",
    "\n",
    "def formula_objective(trial):\n",
    "    w0 = trial.suggest_float(\"w0\", 0.0, 1.0)\n",
    "    w1_base = trial.suggest_float(\"w1_base\", 0.0, 1.0)\n",
    "    w1_rank = trial.suggest_float(\"w1_rank\", 0.0, 1.0)\n",
    "    w_ipcw = trial.suggest_float(\"w_ipcw\", 0.0, 1.0)\n",
    "\n",
    "    c_indices = []\n",
    "    for train_idx, val_idx in kf.split(proba):\n",
    "        prob_e0 = 1 - proba[val_idx]\n",
    "        prob_e1 = proba[val_idx]\n",
    "\n",
    "        risk = (\n",
    "            prob_e0 * w0 * rank_e0[val_idx]\n",
    "            + prob_e1 * (w1_base + w1_rank * rank_e1[val_idx])\n",
    "        )\n",
    "        risk_scores = pd.Series(risk).rank().values / len(risk)\n",
    "\n",
    "        c_idx = compute_ipcw_cindex(\n",
    "            y_times[train_idx],\n",
    "            events[train_idx],\n",
    "            y_times[val_idx],\n",
    "            events[val_idx],\n",
    "            risk_scores,\n",
    "        )\n",
    "        c_indices.append(c_idx)\n",
    "\n",
    "    return -np.mean(c_indices)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(formula_objective, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "formula_params = study.best_params\n",
    "formula_score = -study.best_value\n",
    "\n",
    "print(f\"\\nBest params: {formula_params}\")\n",
    "print(f\"Formula IPCW C-index: {formula_score:.4f}\")\n",
    "\n",
    "# Apply formula\n",
    "prob_e0 = 1 - proba\n",
    "prob_e1 = proba\n",
    "formula_risk = (\n",
    "    prob_e0 * formula_params[\"w0\"] \n",
    "    + prob_e1 * (formula_params[\"w1_base\"] + formula_params[\"w1_rank\"] )\n",
    "    \n",
    ")\n",
    "formula_risk = pd.Series(formula_risk).rank().values / len(formula_risk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea937fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "META-MODELS\n",
      "============================================================\n",
      "\n",
      "--- XGB ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.181687:   7%|▋         | 2/30 [00:10<02:26,  5.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2026-01-26 03:42:13,672]\u001b[0m Trial 2 failed with parameters: {'n_estimators': 11, 'max_depth': 7, 'learning_rate': 0.1091896572547298, 'subsample': 0.9328944524288025, 'colsample_bytree': 0.7765903263154738, 'reg_lambda': 0.2604125420478061, 'reg_alpha': 5.918205359029644} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\"\u001b[0m, line \u001b[35m206\u001b[0m, in \u001b[35m_run_trial\u001b[0m\n",
      "    value_or_values = func(trial)\n",
      "  File \u001b[35m\"C:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\src\\ens_data_challenge\\training\\trainers.py\"\u001b[0m, line \u001b[35m270\u001b[0m, in \u001b[35mobjective\u001b[0m\n",
      "    \u001b[31mmodel.fit\u001b[0m\u001b[1;31m(X_tr, y_tr, sample_weight=weights)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m774\u001b[0m, in \u001b[35minner_f\u001b[0m\n",
      "    return func(**kwargs)\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\"\u001b[0m, line \u001b[35m1365\u001b[0m, in \u001b[35mfit\u001b[0m\n",
      "    self._Booster = \u001b[31mtrain\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                    \u001b[31m~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mparams,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^\u001b[0m\n",
      "    ...<9 lines>...\n",
      "        \u001b[1;31mcallbacks=self.callbacks,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m774\u001b[0m, in \u001b[35minner_f\u001b[0m\n",
      "    return func(**kwargs)\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\training.py\"\u001b[0m, line \u001b[35m199\u001b[0m, in \u001b[35mtrain\u001b[0m\n",
      "    \u001b[31mbst.update\u001b[0m\u001b[1;31m(dtrain, iteration=i, fobj=obj)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m2430\u001b[0m, in \u001b[35mupdate\u001b[0m\n",
      "    \u001b[31mself._assign_dmatrix_features\u001b[0m\u001b[1;31m(dtrain)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m3396\u001b[0m, in \u001b[35m_assign_dmatrix_features\u001b[0m\n",
      "    \u001b[31mself._validate_features\u001b[0m\u001b[1;31m(fn)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m3399\u001b[0m, in \u001b[35m_validate_features\u001b[0m\n",
      "    if \u001b[1;31mself.feature_names\u001b[0m is None:\n",
      "       \u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m2351\u001b[0m, in \u001b[35mfeature_names\u001b[0m\n",
      "    return \u001b[31mself._get_feature_info\u001b[0m\u001b[1;31m(\"feature_name\")\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m2301\u001b[0m, in \u001b[35m_get_feature_info\u001b[0m\n",
      "    \u001b[31m_LIB.XGBoosterGetStrFeatureInfo\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mself.handle,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<2 lines>...\n",
      "        \u001b[1;31mctypes.byref(sarr),\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n",
      "\u001b[33m[W 2026-01-26 03:42:13,685]\u001b[0m Trial 2 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m meta_model_names:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     oof, models, cv_results, params = \u001b[43mtrain_regressor_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_ipcw\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_FOLDS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRANDOM_STATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     meta_results[model_name] = {\n\u001b[32m     26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moof\u001b[39m\u001b[33m\"\u001b[39m: oof,\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m: models,\n\u001b[32m     28\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv_results\u001b[39m\u001b[33m\"\u001b[39m: cv_results,\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: params,\n\u001b[32m     30\u001b[39m     }\n\u001b[32m     32\u001b[39m oof_meta = np.mean([r[\u001b[33m\"\u001b[39m\u001b[33moof\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m meta_results.values()], axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\competitions\\ens_data_challenge\\src\\ens_data_challenge\\training\\trainers.py:321\u001b[39m, in \u001b[36mtrain_regressor_cv\u001b[39m\u001b[34m(X, y_times, events, model_name, subset_mask, use_ipcw, n_folds, n_trials, random_state, verbose)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# Optimize\u001b[39;00m\n\u001b[32m    320\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# Train final\u001b[39;00m\n\u001b[32m    324\u001b[39m oof = np.zeros(\u001b[38;5;28mlen\u001b[39m(y_times))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:68\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:165\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:263\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    256\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    259\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    262\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:206\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    209\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\competitions\\ens_data_challenge\\src\\ens_data_challenge\\training\\trainers.py:270\u001b[39m, in \u001b[36mtrain_regressor_cv.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    268\u001b[39m weights = get_ipcw_weights(times_tr, events[train_idx]).values\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    272\u001b[39m     model.fit(X_tr, y_tr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1365\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1363\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\training.py:199\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:2430\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtrain, DMatrix):\n\u001b[32m   2429\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minvalid training matrix: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dtrain).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2430\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_assign_dmatrix_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2433\u001b[39m     _check_call(\n\u001b[32m   2434\u001b[39m         _LIB.XGBoosterUpdateOneIter(\n\u001b[32m   2435\u001b[39m             \u001b[38;5;28mself\u001b[39m.handle, ctypes.c_int(iteration), dtrain.handle\n\u001b[32m   2436\u001b[39m         )\n\u001b[32m   2437\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:3396\u001b[39m, in \u001b[36mBooster._assign_dmatrix_features\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   3393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3394\u001b[39m     \u001b[38;5;28mself\u001b[39m.feature_types = ft\n\u001b[32m-> \u001b[39m\u001b[32m3396\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:3399\u001b[39m, in \u001b[36mBooster._validate_features\u001b[39m\u001b[34m(self, feature_names)\u001b[39m\n\u001b[32m   3398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, feature_names: Optional[FeatureNames]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_names\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3400\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   3402\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:2351\u001b[39m, in \u001b[36mBooster.feature_names\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2345\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   2346\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeature_names\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Optional[FeatureNames]:\n\u001b[32m   2347\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Feature names for this booster.  Can be directly set by input data or by\u001b[39;00m\n\u001b[32m   2348\u001b[39m \u001b[33;03m    assignment.\u001b[39;00m\n\u001b[32m   2349\u001b[39m \n\u001b[32m   2350\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2351\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_feature_info\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeature_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:2301\u001b[39m, in \u001b[36mBooster._get_feature_info\u001b[39m\u001b[34m(self, field)\u001b[39m\n\u001b[32m   2298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhandle\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2300\u001b[39m _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2301\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterGetStrFeatureInfo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2302\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2304\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43msarr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2306\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2307\u001b[39m )\n\u001b[32m   2308\u001b[39m feature_info = from_cstr_to_pystr(sarr, length)\n\u001b[32m   2309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m feature_info \u001b[38;5;28;01mif\u001b[39;00m feature_info \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 10: META-MODELS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"META-MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "meta_model_names = [\"XGB\", \"LGBM\", \"Ridge\"]\n",
    "meta_results = {}\n",
    "\n",
    "for model_name in meta_model_names:\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    oof, models, cv_results, params = train_regressor_cv(\n",
    "        X_meta,\n",
    "        y_times,\n",
    "        events,\n",
    "        model_name,\n",
    "        use_ipcw=True,\n",
    "        n_folds=N_FOLDS,\n",
    "        n_trials=N_TRIALS,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    meta_results[model_name] = {\n",
    "        \"oof\": oof,\n",
    "        \"models\": models,\n",
    "        \"cv_results\": cv_results,\n",
    "        \"params\": params,\n",
    "    }\n",
    "\n",
    "oof_meta = np.mean([r[\"oof\"] for r in meta_results.values()], axis=0)\n",
    "meta_risk = oof_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a77e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL ENSEMBLE: Formula + Meta-Models\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2026-01-26 03:35:10,910]\u001b[0m Trial 0 failed with parameters: {'w_formula': 0.5748521520846346, 'w_meta': 0.7530763656043956} because of the following error: NameError(\"name 'meta_risk' is not defined\").\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\"\u001b[0m, line \u001b[35m206\u001b[0m, in \u001b[35m_run_trial\u001b[0m\n",
      "    value_or_values = func(trial)\n",
      "  File \u001b[35m\"C:\\Users\\enzo.cAo\\AppData\\Local\\Temp\\ipykernel_26828\\690425579.py\"\u001b[0m, line \u001b[35m16\u001b[0m, in \u001b[35mensemble_objective\u001b[0m\n",
      "    combined = (w_formula / w_sum) * formula_risk + (w_meta / w_sum) * \u001b[1;31mmeta_risk\u001b[0m\n",
      "                                                                       \u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mNameError\u001b[0m: \u001b[35mname 'meta_risk' is not defined\u001b[0m\n",
      "\u001b[33m[W 2026-01-26 03:35:10,918]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'meta_risk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -np.mean(c_indices)\n\u001b[32m     33\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m ensemble_params = study.best_params\n\u001b[32m     37\u001b[39m ensemble_score = -study.best_value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:68\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:165\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:263\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    256\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    259\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    262\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:206\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    209\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mensemble_objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     13\u001b[39m w_meta = trial.suggest_float(\u001b[33m\"\u001b[39m\u001b[33mw_meta\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m, \u001b[32m1.0\u001b[39m)\n\u001b[32m     15\u001b[39m w_sum = w_formula + w_meta + \u001b[32m1e-10\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m combined = (w_formula / w_sum) * formula_risk + (w_meta / w_sum) * \u001b[43mmeta_risk\u001b[49m\n\u001b[32m     17\u001b[39m combined_ranked = pd.Series(combined).rank().values / \u001b[38;5;28mlen\u001b[39m(combined)\n\u001b[32m     19\u001b[39m c_indices = []\n",
      "\u001b[31mNameError\u001b[39m: name 'meta_risk' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 11: FINAL ENSEMBLE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL ENSEMBLE: Formula + Meta-Models\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "def ensemble_objective(trial):\n",
    "    w_formula = trial.suggest_float(\"w_formula\", 0.0, 1.0)\n",
    "    w_meta = trial.suggest_float(\"w_meta\", 0.0, 1.0)\n",
    "\n",
    "    w_sum = w_formula + w_meta + 1e-10\n",
    "    combined = (w_formula / w_sum) * formula_risk + (w_meta / w_sum) * meta_risk\n",
    "    combined_ranked = pd.Series(combined).rank().values / len(combined)\n",
    "\n",
    "    c_indices = []\n",
    "    for train_idx, val_idx in kf.split(combined):\n",
    "        c_idx = compute_ipcw_cindex(\n",
    "            y_times[train_idx],\n",
    "            events[train_idx],\n",
    "            y_times[val_idx],\n",
    "            events[val_idx],\n",
    "            combined_ranked[val_idx],\n",
    "        )\n",
    "        c_indices.append(c_idx)\n",
    "\n",
    "    return -np.mean(c_indices)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(ensemble_objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "ensemble_params = study.best_params\n",
    "ensemble_score = -study.best_value\n",
    "\n",
    "print(f\"\\nEnsemble params: {ensemble_params}\")\n",
    "print(f\"Final IPCW C-index: {ensemble_score:.4f}\")\n",
    "\n",
    "# Final predictions\n",
    "w_sum = ensemble_params[\"w_formula\"] + ensemble_params[\"w_meta\"]\n",
    "final_risk = (\n",
    "    ensemble_params[\"w_formula\"] / w_sum * formula_risk\n",
    "    + ensemble_params[\"w_meta\"] / w_sum * meta_risk\n",
    ")\n",
    "final_risk = pd.Series(final_risk).rank().values / len(final_risk)\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"PIPELINE COMPLETE!\")\n",
    "print(f\"Final risk shape: {final_risk.shape}\")\n",
    "print(\"=\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df03a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "META-MODELS\n",
      "============================================================\n",
      "\n",
      "--- XGB ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.124848:  10%|█         | 3/30 [00:07<01:08,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2026-01-26 03:35:26,084]\u001b[0m Trial 3 failed with parameters: {'n_estimators': 1, 'max_depth': 9, 'learning_rate': 0.0193683028176939, 'subsample': 0.8268851348803736, 'colsample_bytree': 0.8145173390470355, 'reg_lambda': 0.01873431932145186, 'reg_alpha': 0.47025005163813194} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\"\u001b[0m, line \u001b[35m206\u001b[0m, in \u001b[35m_run_trial\u001b[0m\n",
      "    value_or_values = func(trial)\n",
      "  File \u001b[35m\"C:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\src\\ens_data_challenge\\training\\trainers.py\"\u001b[0m, line \u001b[35m282\u001b[0m, in \u001b[35mobjective\u001b[0m\n",
      "    pred = model.predict(X_val)\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m774\u001b[0m, in \u001b[35minner_f\u001b[0m\n",
      "    return func(**kwargs)\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\"\u001b[0m, line \u001b[35m1443\u001b[0m, in \u001b[35mpredict\u001b[0m\n",
      "    predts = self.get_booster().inplace_predict(\n",
      "        data=X,\n",
      "    ...<4 lines>...\n",
      "        validate_features=validate_features,\n",
      "    )\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m774\u001b[0m, in \u001b[35minner_f\u001b[0m\n",
      "    return func(**kwargs)\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m2854\u001b[0m, in \u001b[35minplace_predict\u001b[0m\n",
      "    \u001b[31mself._validate_features\u001b[0m\u001b[1;31m(fns)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m3399\u001b[0m, in \u001b[35m_validate_features\u001b[0m\n",
      "    if \u001b[1;31mself.feature_names\u001b[0m is None:\n",
      "       \u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m2351\u001b[0m, in \u001b[35mfeature_names\u001b[0m\n",
      "    return \u001b[31mself._get_feature_info\u001b[0m\u001b[1;31m(\"feature_name\")\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py\"\u001b[0m, line \u001b[35m2301\u001b[0m, in \u001b[35m_get_feature_info\u001b[0m\n",
      "    \u001b[31m_LIB.XGBoosterGetStrFeatureInfo\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mself.handle,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "    ...<2 lines>...\n",
      "        \u001b[1;31mctypes.byref(sarr),\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n",
      "\u001b[33m[W 2026-01-26 03:35:26,103]\u001b[0m Trial 3 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m meta_model_names:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     oof, models, cv_results, params = \u001b[43mtrain_regressor_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_ipcw\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_FOLDS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRANDOM_STATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     meta_results[model_name] = {\n\u001b[32m     26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moof\u001b[39m\u001b[33m\"\u001b[39m: oof,\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m: models,\n\u001b[32m     28\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv_results\u001b[39m\u001b[33m\"\u001b[39m: cv_results,\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: params,\n\u001b[32m     30\u001b[39m     }\n\u001b[32m     32\u001b[39m oof_meta = np.mean([r[\u001b[33m\"\u001b[39m\u001b[33moof\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m meta_results.values()], axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\competitions\\ens_data_challenge\\src\\ens_data_challenge\\training\\trainers.py:321\u001b[39m, in \u001b[36mtrain_regressor_cv\u001b[39m\u001b[34m(X, y_times, events, model_name, subset_mask, use_ipcw, n_folds, n_trials, random_state, verbose)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# Optimize\u001b[39;00m\n\u001b[32m    320\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# Train final\u001b[39;00m\n\u001b[32m    324\u001b[39m oof = np.zeros(\u001b[38;5;28mlen\u001b[39m(y_times))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:68\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:165\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:263\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    256\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    259\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    262\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:206\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    209\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projects\\competitions\\ens_data_challenge\\src\\ens_data_challenge\\training\\trainers.py:282\u001b[39m, in \u001b[36mtrain_regressor_cv.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    279\u001b[39m fold_train_mses.append(train_mse)\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# Val MSE\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m mse = compute_mse(y_val, pred)\n\u001b[32m    284\u001b[39m fold_mses.append(mse)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1443\u001b[39m, in \u001b[36mXGBModel.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_use_inplace_predict():\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m         predts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmargin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1447\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1448\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1450\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1451\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[32m   1452\u001b[39m             cp = import_cupy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:2854\u001b[39m, in \u001b[36mBooster.inplace_predict\u001b[39m\u001b[34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[39m\n\u001b[32m   2852\u001b[39m     data, fns, _ = _transform_pandas_df(data, enable_categorical)\n\u001b[32m   2853\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[32m-> \u001b[39m\u001b[32m2854\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[32m   2856\u001b[39m     data = np.array(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:3399\u001b[39m, in \u001b[36mBooster._validate_features\u001b[39m\u001b[34m(self, feature_names)\u001b[39m\n\u001b[32m   3398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, feature_names: Optional[FeatureNames]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_names\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3400\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   3402\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:2351\u001b[39m, in \u001b[36mBooster.feature_names\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2345\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   2346\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeature_names\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Optional[FeatureNames]:\n\u001b[32m   2347\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Feature names for this booster.  Can be directly set by input data or by\u001b[39;00m\n\u001b[32m   2348\u001b[39m \u001b[33;03m    assignment.\u001b[39;00m\n\u001b[32m   2349\u001b[39m \n\u001b[32m   2350\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2351\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_feature_info\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeature_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\enzo.cAo\\Documents\\Projects\\competitions\\ens_data_challenge\\.venv\\Lib\\site-packages\\xgboost\\core.py:2301\u001b[39m, in \u001b[36mBooster._get_feature_info\u001b[39m\u001b[34m(self, field)\u001b[39m\n\u001b[32m   2298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhandle\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2300\u001b[39m _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2301\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterGetStrFeatureInfo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2302\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2304\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43msarr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2306\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2307\u001b[39m )\n\u001b[32m   2308\u001b[39m feature_info = from_cstr_to_pystr(sarr, length)\n\u001b[32m   2309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m feature_info \u001b[38;5;28;01mif\u001b[39;00m feature_info \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 10: META-MODELS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"META-MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "meta_model_names = [\"XGB\", \"LGBM\", \"Ridge\"]\n",
    "meta_results = {}\n",
    "\n",
    "for model_name in meta_model_names:\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    oof, models, cv_results, params = train_regressor_cv(\n",
    "        X_meta,\n",
    "        y_times,\n",
    "        events,\n",
    "        model_name,\n",
    "        use_ipcw=True,\n",
    "        n_folds=N_FOLDS,\n",
    "        n_trials=N_TRIALS,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    meta_results[model_name] = {\n",
    "        \"oof\": oof,\n",
    "        \"models\": models,\n",
    "        \"cv_results\": cv_results,\n",
    "        \"params\": params,\n",
    "    }\n",
    "\n",
    "oof_meta = np.mean([r[\"oof\"] for r in meta_results.values()], axis=0)\n",
    "meta_risk = oof_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e58d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 11: FINAL ENSEMBLE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL ENSEMBLE: Formula + Meta-Models\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "def ensemble_objective(trial):\n",
    "    w_formula = trial.suggest_float(\"w_formula\", 0.0, 1.0)\n",
    "    w_meta = trial.suggest_float(\"w_meta\", 0.0, 1.0)\n",
    "\n",
    "    w_sum = w_formula + w_meta + 1e-10\n",
    "    combined = (w_formula / w_sum) * formula_risk + (w_meta / w_sum) * meta_risk\n",
    "    combined_ranked = pd.Series(combined).rank().values / len(combined)\n",
    "\n",
    "    c_indices = []\n",
    "    for train_idx, val_idx in kf.split(combined):\n",
    "        c_idx = compute_ipcw_cindex(\n",
    "            y_times[train_idx],\n",
    "            events[train_idx],\n",
    "            y_times[val_idx],\n",
    "            events[val_idx],\n",
    "            combined_ranked[val_idx],\n",
    "        )\n",
    "        c_indices.append(c_idx)\n",
    "\n",
    "    return -np.mean(c_indices)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(ensemble_objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "ensemble_params = study.best_params\n",
    "ensemble_score = -study.best_value\n",
    "\n",
    "print(f\"\\nEnsemble params: {ensemble_params}\")\n",
    "print(f\"Final IPCW C-index: {ensemble_score:.4f}\")\n",
    "\n",
    "# Final predictions\n",
    "w_sum = ensemble_params[\"w_formula\"] + ensemble_params[\"w_meta\"]\n",
    "final_risk = (\n",
    "    ensemble_params[\"w_formula\"] / w_sum * formula_risk\n",
    "    + ensemble_params[\"w_meta\"] / w_sum * meta_risk\n",
    ")\n",
    "final_risk = pd.Series(final_risk).rank().values / len(final_risk)\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"PIPELINE COMPLETE!\")\n",
    "print(f\"Final risk shape: {final_risk.shape}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# CELL 12: RESULTS SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_data = []\n",
    "\n",
    "# Classification\n",
    "for name, r in clf_results.items():\n",
    "    summary_data.append(\n",
    "        {\n",
    "            \"Type\": \"Classification\",\n",
    "            \"Model\": name,\n",
    "            \"IPCW_C\": r[\"cv_results\"].mean_ipcw_c_index,\n",
    "            \"Std\": r[\"cv_results\"].std_ipcw_c_index,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Regression E1\n",
    "for name, r in reg_e1_results.items():\n",
    "    summary_data.append(\n",
    "        {\n",
    "            \"Type\": \"Reg E[r|e=1]\",\n",
    "            \"Model\": name,\n",
    "            \"IPCW_C\": r[\"cv_results\"].mean_ipcw_c_index,\n",
    "            \"Std\": r[\"cv_results\"].std_ipcw_c_index,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Regression E0\n",
    "for name, r in reg_e0_results.items():\n",
    "    summary_data.append(\n",
    "        {\n",
    "            \"Type\": \"Reg E[r|e=0]\",\n",
    "            \"Model\": name,\n",
    "            \"IPCW_C\": r[\"cv_results\"].mean_ipcw_c_index,\n",
    "            \"Std\": r[\"cv_results\"].std_ipcw_c_index,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# IPCW\n",
    "for name, r in reg_ipcw_results.items():\n",
    "    summary_data.append(\n",
    "        {\n",
    "            \"Type\": \"Reg IPCW\",\n",
    "            \"Model\": name,\n",
    "            \"IPCW_C\": r[\"cv_results\"].mean_ipcw_c_index,\n",
    "            \"Std\": r[\"cv_results\"].std_ipcw_c_index,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Meta-models\n",
    "for name, r in meta_results.items():\n",
    "    summary_data.append(\n",
    "        {\n",
    "            \"Type\": \"Meta-Model\",\n",
    "            \"Model\": name,\n",
    "            \"IPCW_C\": r[\"cv_results\"].mean_ipcw_c_index,\n",
    "            \"Std\": r[\"cv_results\"].std_ipcw_c_index,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Final\n",
    "summary_data.append(\n",
    "    {\"Type\": \"Formula\", \"Model\": \"Optimized\", \"IPCW_C\": formula_score, \"Std\": 0.0}\n",
    ")\n",
    "summary_data.append(\n",
    "    {\"Type\": \"FINAL\", \"Model\": \"Ensemble\", \"IPCW_C\": ensemble_score, \"Std\": 0.0}\n",
    ")\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
